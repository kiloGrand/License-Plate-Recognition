{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24d393a2-800a-4ba4-b1ee-f357bb39cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4589e1c2-0079-4825-9f9b-79ab2b3fa43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = ['京', '沪', '津', '渝', '冀', '晋', '蒙', '辽', '吉', '黑',\n",
    "         '苏', '浙', '皖', '闽', '赣', '鲁', '豫', '鄂', '湘', '粤',\n",
    "         '桂', '琼', '川', '贵', '云', '藏', '陕', '甘', '青', '宁',\n",
    "         '新',\n",
    "         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K',\n",
    "         'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "         'W', 'X', 'Y', 'Z', 'I', 'O', '-'\n",
    "         ]\n",
    "CHARS_DICT = {char:i for i, char in enumerate(CHARS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "880c5ea2-bc2d-42ab-88a1-c930990ea723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加椒盐噪声\n",
    "def SaltPepperNoise(src, percetage=0.3):\n",
    "    h, w, c = src.shape\n",
    "    SP_NoiseImg = src.copy()\n",
    "    SP_NoiseNum = int(percetage*h*w)\n",
    "    for i in range(SP_NoiseNum):\n",
    "        randR = np.random.randint(0, h)\n",
    "        randG = np.random.randint(0, w)\n",
    "        randB = np.random.randint(0, 3)\n",
    "        if random.random() > 0.5:\n",
    "            SP_NoiseImg[randR, randG, randB] = 0\n",
    "        else:\n",
    "            SP_NoiseImg[randR, randG, randB] = 255\n",
    "    return SP_NoiseImg\n",
    "\n",
    "# 高斯噪声\n",
    "def GaussianNoise(image, mean=0, sigma=1):\n",
    "    image = image / 255.0\n",
    "    noise = np.random.normal(mean, sigma, image.shape)\n",
    "    G_Noiseimg = image + noise\n",
    "    G_Noiseimg = np.clip(G_Noiseimg, a_max=255, a_min=0)\n",
    "    G_Noiseimg = np.uint8(G_Noiseimg*255)\n",
    "    return G_Noiseimg\n",
    "\n",
    "# 旋转\n",
    "def rotate(image, angle=90, center=None, scale=1.0):\n",
    "    (h, w) = image.shape[:2]\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "    m = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, m, (w, h))\n",
    "    return rotated\n",
    "\n",
    "# 翻转\n",
    "def flip(image):\n",
    "    flipped_image = np.fliplr(image)\n",
    "    return flipped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f3a0bf3b-3155-435d-ab8a-0789ce74a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPRDataSet(Dataset):\n",
    "    def __init__(self, img_dir, imgSize, lpr_max_len, PreprocFun=None, mode='test'):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_paths = []\n",
    "        if type(img_dir) == str:  # 一个路径\n",
    "            for img_name in os.listdir(img_dir):\n",
    "                img_name = os.path.join(img_dir, img_name)\n",
    "                self.img_paths.append(img_name)\n",
    "        else:\n",
    "            print('error in img_dir, img_dir must be str or list')\n",
    "        random.shuffle(self.img_paths)        # 打乱顺序\n",
    "        self.img_size = imgSize\n",
    "        self.lpr_max_len = lpr_max_len\n",
    "        if PreprocFun is not None:\n",
    "            self.PreprocFun = PreprocFun\n",
    "        elif PreprocFun is None and mode == 'train':\n",
    "            self.PreprocFun = self.train_transform\n",
    "        elif PreprocFun is None and mode == 'test':\n",
    "            self.PreprocFun = self.test_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.img_paths[index]\n",
    "        image = cv2.imread(filename)\n",
    "        height, width, _ = image.shape\n",
    "        if width != self.img_size[0] or height != self.img_size[1]:\n",
    "            image = cv2.resize(image, self.img_size)  # 缩放\n",
    "        # image = image.astype('float32')\n",
    "        # (height, width, channel) -> (channel, height, width) eg:(24,94,3)->(3,24,94) \n",
    "        # image = np.transpose(image, (2, 0, 1))\n",
    "        image = self.PreprocFun(image)\n",
    "\n",
    "        basename = os.path.basename(filename)\n",
    "        imgname, suffix = os.path.splitext(basename)\n",
    "        if int(imgname) < 9:\n",
    "            imgname = '粤GDH078'\n",
    "        else:\n",
    "            imgname = '粤DSTU01'\n",
    "        label = list()\n",
    "        for c in imgname:\n",
    "            label.append(CHARS_DICT[c])\n",
    "\n",
    "        if len(label) > self.lpr_max_len:\n",
    "            print(imgname)\n",
    "            assert 0, \"Error label ^~^!!!\"\n",
    "\n",
    "        return image, label, len(label)\n",
    "\n",
    "    def test_transform(self, img):\n",
    "        img = img.astype('float32')\n",
    "        img -= 127.5\n",
    "        img *= 0.0078125\n",
    "        # (height, width, channel) -> (channel, height, width) eg:(24,94,3)->(3,24,94) \n",
    "        img = np.transpose(img, (2, 0, 1)) \n",
    "        return img\n",
    "\n",
    "    def train_transform(self, img):\n",
    "        img = img.astype('float32')\n",
    "        p = random.uniform(0, 0.2)\n",
    "        img = SaltPepperNoise(img, p)\n",
    "        p = random.randint(0, 5)\n",
    "        img = rotate(img, p)\n",
    "        img -= 127.5\n",
    "        img *= 0.0078125\n",
    "        # (height, width, channel) -> (channel, height, width) eg:(24,94,3)->(3,24,94) \n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd2214fa-1e7a-4421-817b-50c0ae7b8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = LPRDataSet('./data/demo/', (94, 24), 8, mode='train')\n",
    "train_data.img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2fe98874-d056-4314-a379-8512c04a162a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=94x24 at 0x7F7CD5394A00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label, length = train_data[0]\n",
    "image = np.transpose(img, (1, 2, 0)) / 0.0078125 + 127.5\n",
    "image = image.astype(np.uint8)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = Image.fromarray(image)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26989c58-d352-4b46-829b-c81fdfb2268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = LPRDataSet('./data/demo/', (94, 24), 8, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0986cc7f-0df4-40cc-a8bf-c8437a152e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=94x24 at 0x7F7CB3943E20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label, length = test_data[0]\n",
    "image = np.transpose(img, (1, 2, 0)) / 0.0078125 + 127.5\n",
    "image = image.astype(np.uint8)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = Image.fromarray(image)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06b520b7-2efe-4677-a7d8-f261e8d86d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(preds, pred_char=False):\n",
    "    last_chars_idx = len(CHARS) - 1\n",
    "\n",
    "    # 贪婪解码 (greedy decode)\n",
    "    pred_labels = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i, :, :]  # 第i张图片对应的结果，即维度为(66, 18)的二维数组\n",
    "        pred_label = []\n",
    "        for j in range(pred.shape[1]):  # 遍历每一列，找到每一列最大值的索引（index）\n",
    "            pred_label.append(np.argmax(pred[:, j], axis=0))\n",
    "        no_repeat_blank_label = []\n",
    "        pre_c = -1\n",
    "        for c in pred_label:  # 合并重复的索引值部分，删除空白标签，即为-1的值(dropout repeate label and blank label)\n",
    "            if (pre_c == c) or (c == last_chars_idx):\n",
    "                if c == last_chars_idx:\n",
    "                    pre_c = c\n",
    "                continue\n",
    "            no_repeat_blank_label.append(c)\n",
    "            pre_c = c\n",
    "        pred_labels.append(no_repeat_blank_label)\n",
    "\n",
    "    # 解码成字符串\n",
    "    if pred_char:\n",
    "        labels = []\n",
    "        for label in pred_labels:\n",
    "            lb = \"\"\n",
    "            for i in label:\n",
    "                lb += CHARS[i]\n",
    "            labels.append(lb)\n",
    "        return pred_labels, labels\n",
    "    else:\n",
    "        return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a901fe03-0e1a-48f7-b319-8b2385c4b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e406f11-4cd4-47fe-9212-ae5938ed7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class small_basic_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(small_basic_block, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class LPRNet(nn.Module):\n",
    "    def __init__(self, lpr_max_len, class_num, dropout_rate):\n",
    "        super(LPRNet, self).__init__()\n",
    "        self.lpr_max_len = lpr_max_len\n",
    "        self.class_num = class_num\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1), # 0\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),  # 2\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1)),\n",
    "            small_basic_block(ch_in=64, ch_out=128),    # *** 4 ***\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),  # 6\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2)),\n",
    "            small_basic_block(ch_in=64, ch_out=256),   # 8\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),  # 10\n",
    "            small_basic_block(ch_in=256, ch_out=256),   # *** 11 ***\n",
    "            nn.BatchNorm2d(num_features=256),   # 12\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2)),  # 14\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 4), stride=1),  # 16\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),  # 18\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(in_channels=256, out_channels=class_num, kernel_size=(13, 1), stride=1), # 20\n",
    "            nn.BatchNorm2d(num_features=class_num),\n",
    "            nn.ReLU(),  # *** 22 ***\n",
    "        )\n",
    "        self.container = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=448+self.class_num, out_channels=self.class_num, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            # nn.BatchNorm2d(num_features=self.class_num),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(in_channels=self.class_num, out_channels=self.lpr_max_len+1, kernel_size=3, stride=2),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        keep_features = list()\n",
    "        for i, layer in enumerate(self.backbone.children()):\n",
    "            x = layer(x)\n",
    "            if i in [2, 6, 13, 22]: # [2, 4, 8, 11, 22]\n",
    "                keep_features.append(x)\n",
    "\n",
    "        global_context = list()\n",
    "        for i, f in enumerate(keep_features):\n",
    "            if i in [0, 1]:\n",
    "                f = nn.AvgPool2d(kernel_size=5, stride=5)(f)\n",
    "            if i in [2]:\n",
    "                f = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))(f)\n",
    "            f_pow = torch.pow(f, 2)\n",
    "            f_mean = torch.mean(f_pow)\n",
    "            f = torch.div(f, f_mean)\n",
    "            global_context.append(f)\n",
    "\n",
    "        x = torch.cat(global_context, 1)\n",
    "        x = self.container(x)\n",
    "        logits = torch.mean(x, dim=2)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fdc1790-5f0f-4c1e-b194-563b3e519272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "796bc5a9-5e74-49c1-860d-c8a93eb9720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = LPRDataSet('./data/demo/', (94, 24), 8, mode='train')\n",
    "test_data = LPRDataSet('./data/demo/', (94, 24), 8, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90782208-521c-410d-8a84-d2c2af772888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LPRNet(lpr_max_len=8, class_num=len(CHARS), dropout_rate=0.5)\n",
    "dic = torch.load('./weights/Final_LPRNet_model.pth', map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aa9de706-9c93-4a8e-8d72-e8ff086a3b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using  cpu\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "\n",
    "# 损失函数 reduction: 'none' | 'mean' | 'sum'\n",
    "ctc_loss = nn.CTCLoss(blank=len(CHARS)-1, reduction='mean')\n",
    "\n",
    "# 优化器\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# cpu训练还是GPU训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using ', device)\n",
    "model = model.to(device)\n",
    "\n",
    "# tensorboard\n",
    "log_folder = \"./logs/demo\"\n",
    "if not os.path.exists(log_folder):\n",
    "    os.mkdir(log_folder)\n",
    "writer = SummaryWriter(log_dir=log_folder)\n",
    "\n",
    "# 模型保存路径\n",
    "save_folder = './weights'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13b35b46-e4c4-40f5-8d97-1f21046e4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    for sample in batch:\n",
    "        img, label, length = sample\n",
    "        imgs.append(torch.from_numpy(img))\n",
    "        # imgs.append(img)\n",
    "        labels.extend(label)\n",
    "        lengths.append(length)\n",
    "    labels = np.asarray(labels).flatten().astype(np.int32)\n",
    "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n",
    "\n",
    "\n",
    "# 利用DataLoader加载数据集\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size,\n",
    "                          shuffle=True, drop_last=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, collate_fn=collate_fn,\n",
    "                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09e9fef4-6923-47e6-89d6-79111a69d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zhuanlan.zhihu.com/p/67415439\n",
    "def sparse_tuple_for_ctc(T_length=18, lengths=8):\n",
    "    # T_length >= 2*lengths+1, lengths <= lpr_max_len\n",
    "    input_lengths = []\n",
    "    target_lengths = []\n",
    "\n",
    "    for ch in lengths:\n",
    "        input_lengths.append(T_length)\n",
    "        target_lengths.append(ch)\n",
    "\n",
    "    return tuple(input_lengths), tuple(target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d31a09a1-ac3d-40be-8ca4-a668ecab634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----第1轮训练开始-----\n",
      "训练次数：0，loss：17.994121551513672\n",
      "整体测试集上的acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 训练和测试\n",
    "verbose_step = 1\n",
    "total_train_step = 0  # 记录训练次数\n",
    "total_test_step = 0   # 记录测试次数\n",
    "acc = 0.55\n",
    "for i in range(epoch):\n",
    "    print(\"-----第{}轮训练开始-----\".format(i+1))\n",
    "\n",
    "    # 训练\n",
    "    model.train()  # 开启训练模式\n",
    "    for images, labels, lengths in train_loader:\n",
    "        # get ctc parameters\n",
    "        input_lengths, target_lengths = sparse_tuple_for_ctc(lengths=lengths)\n",
    "        # forward\n",
    "        images = images.to(device)\n",
    "        logits = model(images)\n",
    "        log_probs = logits.permute(2, 0, 1) # for ctc loss: T x N x C\n",
    "        log_probs = log_probs.log_softmax(2).requires_grad_()\n",
    "        # backprop\n",
    "        optimizer.zero_grad()  # 优化器中的参数梯度归零\n",
    "        loss = ctc_loss(log_probs, labels, input_lengths=input_lengths, target_lengths=target_lengths)\n",
    "        if loss.item() == np.inf:  # 如果梯度爆炸\n",
    "            continue\n",
    "        loss.backward()        # 反向传播，计算梯度\n",
    "        optimizer.step()       # 优化网络\n",
    "        # 记录loss\n",
    "        if total_train_step % verbose_step == 0:  # 每verbose_step个batch，显示信息\n",
    "            print(\"训练次数：{}，loss：{}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "            writer.add_images(\"Epoch\".format(epoch), images, total_train_step)\n",
    "        total_train_step += 1\n",
    "\n",
    "    # 测试\n",
    "    model.eval()  # 开启测试模式\n",
    "    total_test_loss = 0\n",
    "    total_acc_num = 0\n",
    "    Tp, Tn = 0.0, 0.0\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        for images, labels, lengths in test_loader:\n",
    "            # labels: 1D -> 2D\n",
    "            targets = []\n",
    "            start = 0\n",
    "            for length in lengths:\n",
    "                label = labels[start:start+length]\n",
    "                targets.append(label.tolist())\n",
    "                start += length\n",
    "            # forward\n",
    "            images = images.to(device)\n",
    "            prebs = model(images)\n",
    "            prebs = prebs.cpu().detach().numpy()\n",
    "            # greedy decode\n",
    "            preb_labels = greedy_decode(prebs)\n",
    "            # calculate\n",
    "            for i, label in enumerate(preb_labels):\n",
    "                if len(label) != len(targets[i]):  # 长度不一致\n",
    "                    Tn += 1\n",
    "                    continue\n",
    "                if targets[i] == label:\n",
    "                    Tp += 1\n",
    "                else:\n",
    "                    Tn += 1\n",
    "        total_test_acc = float(Tp) / float(Tp + Tn)\n",
    "        print(\"整体测试集上的acc: {}\".format(total_test_acc))\n",
    "        writer.add_scalar(\"test_acc\", total_test_acc, total_test_step)\n",
    "        total_test_step += 1\n",
    "\n",
    "    # 保存模型参数\n",
    "    if total_test_acc >= acc:  # 保存最好的\n",
    "        acc = total_test_acc\n",
    "        model_path = save_folder + \"/demo_{:.2f}.pth\".format(acc)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"模型已保存\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f8f68-5453-4311-91a6-6ac62f92471e",
   "metadata": {},
   "source": [
    "### 查看acc/loss曲线、训练的照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966f029-772d-4ef0-8089-f8c11758cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cdd617-df07-401b-a49b-cb5473295dc0",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5d823aa3-f0c1-4cad-bc75-5a99dd8625b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体测试集上的acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "Tp, Tn = 0.0, 0.0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()  # 开启测试模式\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for images, labels, lengths in test_loader:\n",
    "        # labels: 1D -> 2D\n",
    "        targets = []\n",
    "        start = 0\n",
    "        for length in lengths:\n",
    "            label = labels[start:start+length]\n",
    "            targets.append(label.tolist())\n",
    "            start += length\n",
    "        # forward\n",
    "        images = images.to(device)\n",
    "        prebs = model(images)\n",
    "        prebs = prebs.cpu().detach().numpy()\n",
    "        # greedy decode\n",
    "        preb_labels = greedy_decode(prebs)\n",
    "        # calculate\n",
    "        for i, label in enumerate(preb_labels):\n",
    "            if len(label) != len(targets[i]):  # 长度不一致\n",
    "                Tn += 1\n",
    "                continue\n",
    "            if targets[i] == label:\n",
    "                Tp += 1\n",
    "            else:\n",
    "                Tn += 1\n",
    "    total_test_acc = float(Tp) / float(Tp + Tn)\n",
    "    print(\"整体测试集上的acc: {}\".format(total_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560317b8-ad45-4ce6-b7e6-c0359d3da9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
